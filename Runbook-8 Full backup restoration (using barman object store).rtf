{\rtf1\ansi\ansicpg1252\cocoartf2761
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 ArialMT;\f1\fswiss\fcharset0 Arial-BoldMT;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red164\green8\blue3;\red63\green105\blue30;
\red253\green128\blue8;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c71055\c10387\c0;\cssrgb\c30831\c47797\c15540;
\cssrgb\c100000\c57637\c0;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}}
{\info
{\author Swapnil Suryawanshi}}\paperw11900\paperh16840\margl1440\margr1440\vieww35640\viewh22400\viewkind0
\deftab720
\pard\pardeftab720\sa240\partightenfactor0

\f0\fs40 \cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 This test case outlines the steps to restore a full backup in a CloudNativePG (CNPG) PostgreSQL cluster.\
\
\pard\pardeftab720\sa298\partightenfactor0

\f1\b \cf3 \strokec2 Prerequisites\cf0 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls1\ilvl0
\f0\b0 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Existing PostgreSQL cluster: 
\f1\b cluster-backup, 
\f0\b0 created in runbook-4\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}
\f1\b \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Backup name: pg-full
\f0\b0  \outl0\strokewidth0 created in runbook-4\outl0\strokewidth0 \strokec2 \
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 AWS 
\f1\b S3 bucket containing the backup
\f0\b0  \outl0\strokewidth0 created in runbook-4
\f1\b \
\pard\tx720\pardeftab720\sa240\partightenfactor0

\f0\b0 \cf0 \outl0\strokewidth0 \strokec2 \
\pard\pardeftab720\sa298\partightenfactor0

\f1\b \cf4 Step 1: Verify Backup Status\cf0 \
\pard\pardeftab720\sa280\partightenfactor0
\cf0 Command:\
\pard\pardeftab720\partightenfactor0

\f0\b0 \cf5 \strokec2 kubectl get backup -n backup\cf0 \
\
\pard\pardeftab720\sa280\partightenfactor0

\f1\b \cf0 \strokec2 Expected Output:\
\pard\pardeftab720\partightenfactor0

\f0\b0 \cf0 \strokec2 NAME       AGE    CLUSTER          METHOD              PHASE       ERROR\
pg-full    2m4s   cluster-backup   barmanObjectStore   completed   \
\
\pard\pardeftab720\sa298\partightenfactor0

\f1\b \cf4 \strokec2 Step 2: Verify Backup in S3 Bucket\cf0 \
\pard\pardeftab720\sa280\partightenfactor0
\cf0 Command:\
\pard\pardeftab720\partightenfactor0

\f0\b0 \cf5 \strokec2 aws s3 ls s3://swapnil-backup/test/cluster-backup/ --human-readable --summarize --recursive\cf0 \
\
\pard\pardeftab720\sa280\partightenfactor0

\f1\b \cf0 \strokec2 Expected Output:\
\pard\pardeftab720\partightenfactor0

\f0\b0 \cf0 \strokec2 2025-01-23 19:34:18    1.4 KiB test/cluster-backup/base/20250123T140331/backup.info\
2025-01-23 19:33:39   31.2 MiB test/cluster-backup/base/20250123T140331/data.tar\
...\
Total Objects: 13\
Total Size: 174.3 MiB\
\
\pard\pardeftab720\sa298\partightenfactor0

\f1\b \cf4 \strokec2 Step 3: Create the Restore Manifest\cf0 \
\pard\pardeftab720\partightenfactor0

\f0\b0 \cf5 \outl0\strokewidth0 vi cluster-restore-full.yaml\

\f1\b \cf0 \outl0\strokewidth0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f0\b0 \cf0 \strokec2 apiVersion: postgresql.cnpg.io/v1\
kind: Cluster\
metadata:\
  name: cluster-restore-full\
  namespace: backup\
spec:\
  logLevel: info\
  startDelay: 30\
  stopDelay: 30\
  nodeMaintenanceWindow:\
    inProgress: false\
    reusePVC: true\
  backup:\
    target: primary\
  enableSuperuserAccess: true\
  monitoring:\
    disableDefaultQueries: false\
    enablePodMonitor: false\
  minSyncReplicas: 0\
  postgresGID: 26\
  replicationSlots:\
    highAvailability:\
      slotPrefix: _cnp_\
    updateInterval: 30\
  primaryUpdateMethod: switchover\
  bootstrap:\
    recovery:\
      backup:\
        name: pg-full\
  failoverDelay: 0\
  postgresUID: 26\
  walStorage:\
    resizeInUseVolumes: true\
    size: 1G\
  maxSyncReplicas: 0\
  switchoverDelay: 40000000\
  storage:\
    resizeInUseVolumes: true\
    size: 2Gi\
  primaryUpdateStrategy: unsupervised\
  instances: 1\
\
\
\pard\pardeftab720\sa298\partightenfactor0

\f1\b \cf4 \strokec2 Step 4: Apply the Restore Manifest\cf0 \
\pard\pardeftab720\sa280\partightenfactor0
\cf0 Command:\
\pard\pardeftab720\partightenfactor0

\f0\b0 \cf5 \strokec2 kubectl apply -f cluster-restore-full.yaml -n backup\cf0 \
\
\pard\pardeftab720\sa298\partightenfactor0

\f1\b \cf0 \strokec2 Step 5: Verify Pod Status\
\pard\pardeftab720\sa280\partightenfactor0
\cf0 Command:\
\pard\pardeftab720\partightenfactor0

\f0\b0 \cf5 \strokec2 kubectl get pod -n backup -L role\cf0 \
\
\pard\pardeftab720\sa280\partightenfactor0

\f1\b \cf0 \strokec2 Expected Output:\
\pard\pardeftab720\partightenfactor0

\f0\b0 \cf0 \strokec2 NAME                     READY   STATUS    RESTARTS   AGE    ROLE\
cluster-backup-1         1/1     Running   0          32m    primary\
cluster-restore-full-1   1/1     Running   0          5m3s   primary\
\
\pard\pardeftab720\sa298\partightenfactor0

\f1\b \cf4 \strokec2 Step 6: Verify Cluster Status\cf0 \
\pard\pardeftab720\sa280\partightenfactor0
\cf0 Command:\
\pard\pardeftab720\partightenfactor0

\f0\b0 \cf5 \strokec2 kubectl cnpg status cluster-restore-full -n backup\cf0 \
\
\pard\pardeftab720\sa280\partightenfactor0

\f1\b \cf0 \strokec2 Expected Output:\
\pard\pardeftab720\partightenfactor0

\f0\b0 \cf0 \strokec2 Cluster Summary\
Name                 backup/cluster-restore-full\
System ID:           7463110619807920157\
PostgreSQL Image:    ghcr.io/cloudnative-pg/postgresql:17.2\
Primary instance:    cluster-restore-full-1\
Primary start time:  2025-01-23 14:27:53 +0000 UTC (uptime 56s)\
Status:              Cluster in healthy state \
Instances:           1\
Ready instances:     1\
Size:                126M\
Current Write LSN:   0/B0084F0 (Timeline: 2 - WAL File: 00000002000000000000000B)\
\
Continuous Backup status\
First Point of Recoverability:  Not Available\
Working WAL archiving:          OK\
WALs waiting to be archived:    0\
Last Archived WAL:              00000002000000000000000A   @   2025-01-23T14:27:53.624223Z\
Last Failed WAL:                00000002.history           @   2025-01-23T14:27:45.234394Z\
\
Streaming Replication status\
Not configured\
\
Instances status\
Name                    Current LSN  Replication role  Status  QoS         Manager Version  Node\
----                    -----------  ----------------  ------  ---         ---------------  ----\
cluster-restore-full-1  0/B0084F0    Primary           OK      BestEffort  1.25.0           cnpg-1.25.0-control-plane\
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \
}