{\rtf1\ansi\ansicpg1252\cocoartf2761
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\froman\fcharset0 Times-Bold;\f1\froman\fcharset0 Times-Roman;\f2\fmodern\fcharset0 Courier;
\f3\fmodern\fcharset0 Courier-Bold;\f4\fnil\fcharset0 HelveticaNeue;}
{\colortbl;\red255\green255\blue255;\red164\green8\blue3;\red0\green0\blue0;\red0\green0\blue233;
\red109\green109\blue109;\red63\green105\blue30;\red253\green128\blue8;\red206\green59\blue5;\red252\green83\blue8;
\red168\green24\blue75;\red38\green38\blue38;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c71055\c10387\c0;\cssrgb\c0\c0\c0;\cssrgb\c0\c0\c93333;
\cssrgb\c50196\c50196\c50196;\cssrgb\c30831\c47797\c15540;\cssrgb\c100000\c57637\c0;\cssrgb\c85233\c31565\c0;\cssrgb\c100000\c41713\c26;
\cssrgb\c72439\c17643\c36556;\cssrgb\c20000\c20000\c20000;\cssrgb\c100000\c100000\c100000;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid3}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}}
\paperw11900\paperh16840\margl1440\margr1440\vieww35640\viewh19080\viewkind0
\deftab720
\pard\pardeftab720\sa298\partightenfactor0

\f0\b\fs50 \cf2 \expnd0\expndtw0\kerning0
Runbook: Creating and Managing a Replica Cluster in Kubernetes\cf0 \
\pard\pardeftab720\sa240\partightenfactor0

\fs38 \cf0 Reference Documentation:
\f1\b0  {\field{\*\fldinst{HYPERLINK "https://www.enterprisedb.com/docs/postgres_for_kubernetes/latest/replica_cluster/"}}{\fldrslt \cf4 \ul \ulc4 Postgres for Kubernetes Replica Cluster}}\
This test case demonstrates how to set up a replica cluster using the following names:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls1\ilvl0
\f0\b \cf0 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
Primary Cluster:
\f1\b0  
\f2\fs40 cluster-primary
\f1\fs38 \
\ls1\ilvl0
\f0\b \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
Replica Cluster:
\f1\b0  
\f2\fs40 cluster-replica
\f1\fs38 \
\pard\pardeftab720\partightenfactor0
\cf5 \
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs60 \cf2 Steps
\fs42 \cf0 \
\pard\pardeftab720\sa319\partightenfactor0

\fs38 \cf6 1. Create Namespaces\cf0 \
\pard\pardeftab720\partightenfactor0

\f2\b0\fs40 \cf7 kubectl create namespace primary\
kubectl create namespace replica\cf0 \
\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs38 \cf0 Output:
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf0 namespace/primary created\
namespace/replica created\
\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs38 \cf0 Verify namespaces:\
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf7 kubectl get namespace\cf0 \
\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs38 \cf0 Output:
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf0 NAME                 STATUS   AGE\
cnpg-system          Active   9d\
default              Active   9d\
kube-node-lease      Active   9d\
kube-public          Active   9d\
kube-system          Active   9d\
local-path-storage   Active   9d\
primary              Active   24s\
replica              Active   17s\
\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs38 \cf6 2. Create AWS Credentials Secrets\cf0 \
\pard\pardeftab720\partightenfactor0

\f2\b0\fs40 \cf0 kubectl create secret generic aws-creds \\\
--from-literal=ACCESS_KEY_ID=<ACCESS_KEY_ID> \\\
--from-literal=ACCESS_SECRET_KEY=<ACCESS_SECRET_KEY> \cf7 -n primary\cf0 \
\
kubectl create secret generic aws-creds \\\
--from-literal=ACCESS_KEY_ID=<ACCESS_KEY_ID> \\\
--from-literal=ACCESS_SECRET_KEY=<ACCESS_SECRET_KEY> \cf7 -n replica\cf0 \
\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs38 \cf6 3. Create the Primary Cluster\cf0 \
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 Create a YAML file (
\f2\fs40 cluster-primary.yaml
\f1\fs38 ) with the following content:\
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf7 cat <<EOF | sudo tee cluster-primary.yaml\cf0 \
apiVersion: postgresql.cnpg.io/v1\
kind: Cluster\
metadata:\
  name: cluster-primary\
  namespace: primary\
spec:\
  instances: 3\
  primaryUpdateStrategy: unsupervised\
  storage:\
    size: 1G\
  # Persistent storage configuration\
  replica:\
    primary: cluster-primary\
    source: cluster-primary\
  # Backup properties\
  backup:\
    barmanObjectStore:\
      destinationPath: 's3://swapnil-backup/test/'\
      s3Credentials:\
        accessKeyId:\
          key: ACCESS_KEY_ID\
          name: aws-creds\
        inheritFromIAMRole: false\
        secretAccessKey:\
          key: ACCESS_SECRET_KEY\
          name: aws-creds\
  externalClusters:\
  - name: cluster-primary\
    barmanObjectStore:\
      destinationPath: s3://swapnil-backup/test/\
      s3Credentials:\
        accessKeyId:\
          name: aws-creds\
          key: ACCESS_KEY_ID\
        secretAccessKey:\
          name: aws-creds\
          key: ACCESS_SECRET_KEY\
  - name: cluster-replica\
    barmanObjectStore:\
      destinationPath: s3://swapnil-backup/test/\
      s3Credentials:\
        accessKeyId:\
          name: aws-creds\
          key: ACCESS_KEY_ID\
        secretAccessKey:\
          name: aws-creds\
          key: ACCESS_SECRET_KEY\
EOF\
\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs38 \cf0 Apply the configuration:\
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf7 kubectl apply -f cluster-primary.yaml\cf0 \
\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs38 \cf0 Output:
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf0 cluster.postgresql.cnpg.io/cluster-primary created\
\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs38 \cf0 Verify pod status:\
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf7 kubectl get pods -L role -n primary\cf0 \
\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs38 \cf0 Output:
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf0 NAME                READY   STATUS    RESTARTS   AGE   ROLE\
cluster-primary-1   1/1     Running   0          88s   primary\
cluster-primary-2   1/1     Running   0          65s   replica\
cluster-primary-3   1/1     Running   0          45s   replica\
\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs38 \cf6 4. Verify Cluster Status\cf0 \
\pard\pardeftab720\partightenfactor0

\f2\b0\fs40 \cf7 kubectl cnpg status cluster-primary -n primary\cf0 \
\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs38 \cf0 Output:
\f2\b0\fs22 \
\pard\pardeftab720\partightenfactor0

\fs34 \cf0 Cluster Summary\
Name                 primary/cluster-primary\
System ID:           7462718980101066780\
PostgreSQL Image:    ghcr.io/cloudnative-pg/postgresql:17.2\
Primary instance:    cluster-primary-1\
Primary start time:  2025-01-22 12:41:09 +0000 UTC (uptime 1m48s)\
Status:              Cluster in healthy state \
Instances:           3\
Ready instances:     3\
Size:                126M\
Current Write LSN:   0/6050170 (Timeline: 1 - WAL File: 000000010000000000000006)\
\
Continuous Backup status\

\f3\b First Point of Recoverability:  Not Available
\f2\b0 \
Working WAL archiving:          OK\
WALs waiting to be archived:    2\
Last Archived WAL:              000000010000000000000004   @   2025-01-22T12:42:42.148668Z\
Last Failed WAL:                -\
\
Streaming Replication status\
Replication Slots Enabled\
Name               Sent LSN   Write LSN  Flush LSN  Replay LSN  Write Lag  Flush Lag  Replay Lag  State      Sync State  Sync Priority  Replication Slot\
----               --------   ---------  ---------  ----------  ---------  ---------  ----------  -----      ----------  -------------  ----------------\
cluster-primary-2  0/6050170  0/6050170  0/6050170  0/6050170   00:00:00   00:00:00   00:00:00    streaming  async       0              active\
cluster-primary-3  0/6050170  0/6050170  0/6050170  0/6050170   00:00:00   00:00:00   00:00:00    streaming  async       0              active\
\
Instances status\
Name               Current LSN  Replication role  Status  QoS         Manager Version  Node\
----               -----------  ----------------  ------  ---         ---------------  ----\
cluster-primary-1  0/6050170    Primary           OK      BestEffort  1.25.0           cnpg-1.25.0-control-plane\
cluster-primary-2  0/6050170    Standby (async)   OK      BestEffort  1.25.0           cnpg-1.25.0-control-plane\
cluster-primary-3  0/6050170    Standby (async)   OK      BestEffort  1.25.0           cnpg-1.25.0-control-plane              Cluster in healthy state 
\f1\fs38 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\cf0 \
\pard\pardeftab720\sa240\partightenfactor0

\f0\b \cf6 5. Initiate Backup 
\f1\b0 \cf0 \
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf7 kubectl cnpg backup cluster-primary -n primary\cf0 \
\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs38 \cf0 Output:
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf0 backup/cluster-primary-<timestamp> created\
\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs38 \cf0 Verify backup:\
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf7 kubectl get backup -n primary\cf0 \
\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs38 \cf0 Output:
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf0 NAME                             AGE   CLUSTER           METHOD              PHASE       ERROR\
cluster-primary-<timestamp>      28s   cluster-primary   barmanObjectStore   completed 
\f1\fs38 \
\pard\pardeftab720\partightenfactor0
\ls2\ilvl0\cf0 \
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf6 6. Backup Verification\cf0 \
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 Check S3 for WAL and backup files:\
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf7 aws s3 ls s3://swapnil-backup/test/cluster-primary/ --recursive --human-readable --summarize\cf0 \
\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs38 \cf0 Output:
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf0 \
2025-01-22 18:23:10    1.4 KiB test/cluster-primary/base/20250122T125249/backup.info\
2025-01-22 18:22:51   31.4 MiB test/cluster-primary/base/20250122T125249/data.tar\
2025-01-22 18:11:14   16.0 MiB test/cluster-primary/wals/0000000100000000/000000010000000000000001\
2025-01-22 18:11:50   16.0 MiB test/cluster-primary/wals/0000000100000000/000000010000000000000002\
2025-01-22 18:12:05   16.0 MiB test/cluster-primary/wals/0000000100000000/000000010000000000000003\
2025-01-22 18:12:05  338 Bytes test/cluster-primary/wals/0000000100000000/000000010000000000000003.00000028.backup\
2025-01-22 18:12:27   16.0 MiB test/cluster-primary/wals/0000000100000000/000000010000000000000004\
2025-01-22 18:12:44   16.0 MiB test/cluster-primary/wals/0000000100000000/000000010000000000000005\
2025-01-22 18:12:44  338 Bytes test/cluster-primary/wals/0000000100000000/000000010000000000000005.00000028.backup\
2025-01-22 18:17:05   16.0 MiB test/cluster-primary/wals/0000000100000000/000000010000000000000006\
2025-01-22 18:22:07   16.0 MiB test/cluster-primary/wals/0000000100000000/000000010000000000000007\
\
Total Objects: 11\
   Total Size: 143.4 MiB\
\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs38 \cf6 7. Verify Cluster Status\cf0 \
\pard\pardeftab720\partightenfactor0

\f2\b0\fs40 \cf7 kubectl cnpg status cluster-primary -n primary\cf0 \
\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs38 \cf0 Output:\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs34 \cf0 Cluster Summary\
Name                 primary/cluster-primary\
System ID:           7462718980101066780\
PostgreSQL Image:    ghcr.io/cloudnative-pg/postgresql:17.2\
Primary instance:    cluster-primary-1\
Primary start time:  2025-01-22 12:41:09 +0000 UTC (uptime 20m7s)\
Status:              Cluster in healthy state \
Instances:           3\
Ready instances:     3\
Size:                142M\
Current Write LSN:   0/8000000 (Timeline: 1 - WAL File: 000000010000000000000008)\
\
Continuous Backup status\
F
\f3\b irst Point of Recoverability:  2025-01-22T12:52:50Z
\f2\b0 \
Working WAL archiving:          OK\
WALs waiting to be archived:    0\
Last Archived WAL:              000000010000000000000007   @   2025-01-22T12:52:19.438286Z\
Last Failed WAL:                -\
\
Streaming Replication status\
Replication Slots Enabled\
Name               Sent LSN   Write LSN  Flush LSN  Replay LSN  Write Lag  Flush Lag  Replay Lag  State      Sync State  Sync Priority  Replication Slot\
----               --------   ---------  ---------  ----------  ---------  ---------  ----------  -----      ----------  -------------  ----------------\
cluster-primary-2  0/8000000  0/8000000  0/8000000  0/8000000   00:00:00   00:00:00   00:00:00    streaming  async       0              active\
cluster-primary-3  0/8000000  0/8000000  0/8000000  0/8000000   00:00:00   00:00:00   00:00:00    streaming  async       0              active\
\
Instances status\
Name               Current LSN  Replication role  Status  QoS         Manager Version  Node\
----               -----------  ----------------  ------  ---         ---------------  ----\
cluster-primary-1  0/8000000    Primary           OK      BestEffort  1.25.0           cnpg-1.25.0-control-plane\
cluster-primary-2  0/8000000    Standby (async)   OK      BestEffort  1.25.0           cnpg-1.25.0-control-plane\
cluster-primary-3  0/8000000    Standby (async)   OK      BestEffort  1.25.0           cnpg-1.25.0-control-plane
\fs40 \
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs38 \cf6 8. Create the Replica Cluster\cf0 \
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 Create a YAML file (
\f2\fs40 cluster-replica.yaml
\f1\fs38 ) with the following content:\
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf7 cat <<EOF | sudo tee cluster-replica.yaml\cf0 \
apiVersion: postgresql.cnpg.io/v1\
kind: Cluster\
metadata:\
  name: cluster-replica\
  namespace: replica\
spec:\
  instances: 3\
  bootstrap:\
    recovery:\
      source: cluster-primary\
  storage:\
    size: 1Gi\
  replica:\
    primary: cluster-primary\
    source: cluster-primary\
  backup:\
    barmanObjectStore:\
      destinationPath: s3://swapnil-backup/test/\
      s3Credentials:\
        accessKeyId:\
          name: aws-creds\
          key: ACCESS_KEY_ID\
        secretAccessKey:\
          name: aws-creds\
          key: ACCESS_SECRET_KEY         \
  externalClusters:\
  - name: cluster-primary\
    barmanObjectStore:\
      destinationPath: s3://swapnil-backup/test/\
      s3Credentials:\
        accessKeyId:\
          name: aws-creds\
          key: ACCESS_KEY_ID\
        secretAccessKey:\
          name: aws-creds\
          key: ACCESS_SECRET_KEY\
  - name: cluster-replica\
    barmanObjectStore:\
      destinationPath: s3://swapnil-backup/test/\
      s3Credentials:\
        accessKeyId:\
          name: aws-creds\
          key: ACCESS_KEY_ID\
        secretAccessKey:\
          name: aws-creds\
          key: ACCESS_SECRET_KEY                \
EOF\
\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs38 \cf0 Apply the configuration:\
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf7 kubectl apply -f cluster-replica.yaml\cf0 \
\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs38 \cf0 Output:
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf0 cluster.postgresql.cnpg.io/cluster-replica created\
\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs38 \cf0 Verify replica cluster status:\
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf7 kubectl get pods -L role -n replica\cf0 \
\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs38 \cf0 Output:
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf0 NAME                READY   STATUS    RESTARTS   AGE     ROLE\
cluster-replica-1   1/1     Running   0          8m39s   primary\
cluster-replica-2   1/1     Running   0          8m7s    replica\
cluster-replica-3   1/1     Running   0          7m38s   replica\
\
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs38 \cf6 9. Verify Cluster Status\cf0 \
\pard\pardeftab720\partightenfactor0

\f2\b0\fs40 \cf7 kubectl cnpg status cluster-replica -n replica\cf0 \
\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs38 \cf0 Output:\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs34 \cf0 Replica Cluster Summary\
Name                 replica/cluster-replica\
System ID:           7462718980101066780\
PostgreSQL Image:    ghcr.io/cloudnative-pg/postgresql:17.2\
Designated primary:  cluster-replica-1\
Source cluster:      cluster-primary\
Primary start time:  2025-01-22 13:02:49 +0000 UTC (uptime 8m53s)\
Status:              Cluster in healthy state \
Instances:           3\
Ready instances:     3\
Size:                62M\
\
Continuous Backup status\
First Point of Recoverability:  Not Available\
Working WAL archiving:          OK\
WALs waiting to be archived:    0\
Last Archived WAL:              000000010000000000000007   @   2025-01-22T13:03:38.893163Z\
Last Failed WAL:                -\
\
Instances status\
Name               Current LSN  Replication role              Status  QoS         Manager Version  Node\
----               -----------  ----------------              ------  ---         ---------------  ----\
cluster-replica-1  0/8000000    Designated primary            OK      BestEffort  1.25.0           cnpg-1.25.0-control-plane\
cluster-replica-2  0/8000000    Standby (in Replica Cluster)  OK      BestEffort  1.25.0           cnpg-1.25.0-control-plane\
cluster-replica-3  0/8000000    Standby (in Replica Cluster)  OK      BestEffort  1.25.0           cnpg-1.25.0-control-plane\
\
\pard\pardeftab720\partightenfactor0

\fs40 \cf0 \
\pard\pardeftab720\sa319\partightenfactor0

\f0\b\fs48 \cf2 Promotion/Controlled Switchover\
=========================
\fs38 \cf0 \
\pard\pardeftab720\sa240\partightenfactor0

\f1\b0 \cf0 Controlled switchover in a distributed topology is a two-step process involving:\
\
1. Demotion of a primary cluster to a replica cluster\
2. Promotion of a replica cluster to a primary cluster
\f0\b\fs48 \cf2 \
\pard\pardeftab720\sa319\partightenfactor0

\fs38 \cf0 \
\cf6 Step:1 Demotion of a primary cluster to a replica cluster
\f1\b0 \cf0 \
The replica cluster that's been selected to become the new primary, Modify the 
\f2\fs40 primary
\f1\fs38  and 
\f2\fs40 source
\f1\fs38  fields in the 
\f2\fs40 cluster-primary.yaml
\f1\fs38  to point to 
\f2\fs40 cluster-replica
\f1\fs38 :\
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf7 kubectl edit cluster cluster-primary -n primary \cf0 \
\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs38 \cf0 Before:
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf0   replica:\
    primary: cluster-primary\
    source: cluster-primary\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs38 \cf0 After:
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf0   replica:\
    primary: cluster-replica\
    source: cluster-replica\
\pard\pardeftab720\sa240\partightenfactor0

\f1\fs38 \cf0 \
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf6 Step:2 Promotion of a replica cluster to a primary cluster
\f1\b0 \cf0 \
\pard\pardeftab720\sa240\partightenfactor0
\cf8 1] You need to retrieve the 
\f0\b demotionToken
\f1\b0  from 
\f0\b cluster-primary
\f1\b0  using the following command:\cf0 \
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf0 swapnilsuryawanshi@LAPTOP385PNIN runbook-cnp % \cf7 kubectl get cluster cluster-primary -n primary\\\
  -o jsonpath='\{.status.demotionToken\}'\cf0 \
eyJsYXRlc3RDaGVja3BvaW50VGltZWxpbmVJRCI6IjEiLCJyZWRvV2FsRmlsZSI6IjAwMDAwMDAxMDAwMDAwMDAwMDAwMDAwOCIsImRhdGFiYXNlU3lzdGVtSWRlbnRpZmllciI6Ijc0NjI3NDg2MTE5ODU3ODg5NTgiLCJsYXRlc3RDaGVja3BvaW50UkVET0xvY2F0aW9uIjoiMC84MDAwMDI4IiwidGltZU9mTGF0ZXN0Q2hlY2twb2ludCI6IldlZCAyMiBKYW4gMjAyNSAwMjo0MjoxNCBQTSBVVEMiLCJvcGVyYXRvclZlcnNpb24iOiIxLjI1LjAifQ==% \
\
\pard\pardeftab720\partightenfactor0

\f3\b \cf8 Or
\f2\b0  With the 
\f3\b \cf7 kubectl cnpg status <Cluster_name> -n
\f2\b0 \cf8  Namespace 
\f1 command
\f2   \cf0                                                                                                                                                                     
\f1\fs38 \
\
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf0 Replica Cluster Summary\
Name                 primary/cluster-primary\
System ID:           \
PostgreSQL Image:    ghcr.io/cloudnative-pg/postgresql:17.2\
Designated primary:  cluster-primary-1\
Source cluster:      cluster-replica\
Primary start time:  2025-01-22 14:42:15 +0000 UTC (uptime 36s)\
Status:              Applying configuration PostgreSQL configuration changed\
Instances:           3\
Ready instances:     0\
Size:                159M\
\
Demotion token\
Token                              eyJsYXRlc3RDaGVja3BvaW50VGltZWxpbmVJRCI6IjEiLCJyZWRvV2FsRmlsZSI6IjAwMDAwMDAxMDAwMDAwMDAwMDAwMDAwOCIsImRhdGFiYXNlU3lzdGVtSWRlbnRpZmllciI6Ijc0NjI3NDg2MTE5ODU3ODg5NTgiLCJsYXRlc3RDaGVja3BvaW50UkVET0xvY2F0aW9uIjoiMC84MDAwMDI4IiwidGltZU9mTGF0ZXN0Q2hlY2twb2ludCI6IldlZCAyMiBKYW4gMjAyNSAwMjo0MjoxNCBQTSBVVEMiLCJvcGVyYXRvclZlcnNpb24iOiIxLjI1LjAifQ==
\f1\fs38 \
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \
\pard\pardeftab720\sa240\partightenfactor0
\cf8 2] Modify the 
\f2\fs40 primary
\f1\fs38  and 
\f2\fs40 source
\f1\fs38  fields in the 
\f2\fs40 cluster-replica.yaml
\f1\fs38  \cf0 \
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf7 kubectl edit cluster cluster-replica -n replica \cf0 \
\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs38 \cf0 Before:
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf0   replica:\
    primary: cluster-primary\
    source: cluster-primary\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs38 \cf0 After:
\f1\b0 \
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf0   replica:\
    primary: cluster-replica\
    promotionToken: eyJsYXRlc3RDaGVja3BvaW50VGltZWxpbmVJRCI6IjEiLCJyZWRvV2FsRmlsZSI6IjAwMDAwMDAxMDAwMDAwMDAwMDAwMDAwOCIsImRhdGFiYXNlU3lzdGVtSWRlbnRpZmllciI6Ijc0NjI3NDg2MTE5ODU3ODg5NTgiLCJsYXRlc3RDaGVja3BvaW50UkVET0xvY2F0aW9uIjoiMC84MDAwMDI4IiwidGltZU9mTGF0ZXN0Q2hlY2twb2ludCI6IldlZCAyMiBKYW4gMjAyNSAwMjo0MjoxNCBQTSBVVEMiLCJvcGVyYXRvclZlcnNpb24iOiIxLjI1LjAifQ==\
    source: cluster-primary
\f1\fs38 \
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \
\pard\pardeftab720\sa319\partightenfactor0

\f0\b \cf6 9. Verify both Cluster Status\
\pard\pardeftab720\sa319\partightenfactor0

\f1\b0 \cf9 1] Ex primary cluster status:
\f0\b \cf0 \
\pard\pardeftab720\partightenfactor0

\f2\b0\fs40 \cf7 kubectl cnpg status cluster-primary -n primary\cf0 \
\
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs38 \cf0 Output:\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs34 \cf0 Replica Cluster Summary\
Name                 primary/cluster-primary\
System ID:           7462748611985788958\
PostgreSQL Image:    ghcr.io/cloudnative-pg/postgresql:17.2\
Designated primary:  cluster-primary-1\
Source cluster:      cluster-replica\
Primary start time:  2025-01-22 14:42:15 +0000 UTC (uptime 3m44s)\
Status:              Cluster in healthy state \
Instances:           3\
Ready instances:     3\
Size:                170M\
\
Demotion token\
Token                              eyJsYXRlc3RDaGVja3BvaW50VGltZWxpbmVJRCI6IjEiLCJyZWRvV2FsRmlsZSI6IjAwMDAwMDAxMDAwMDAwMDAwMDAwMDAwOCIsImRhdGFiYXNlU3lzdGVtSWRlbnRpZmllciI6Ijc0NjI3NDg2MTE5ODU3ODg5NTgiLCJsYXRlc3RDaGVja3BvaW50UkVET0xvY2F0aW9uIjoiMC84MDAwMDI4IiwidGltZU9mTGF0ZXN0Q2hlY2twb2ludCI6IldlZCAyMiBKYW4gMjAyNSAwMjo0MjoxNCBQTSBVVEMiLCJvcGVyYXRvclZlcnNpb24iOiIxLjI1LjAifQ==\
Validity                           valid\
Latest checkpoint's TimeLineID     1\
Latest checkpoint's REDO WAL file  000000010000000000000008\
Latest checkpoint's REDO location  0/8000028\
Database system identifier         7462748611985788958 (ok)\
Time of latest checkpoint          Wed 22 Jan 2025 02:42:14 PM UTC\
Version of the operator            1.25.0\
\
Continuous Backup status\
First Point of Recoverability:  2025-01-22T14:37:41Z\
Working WAL archiving:          OK\
WALs waiting to be archived:    0\
Last Archived WAL:              000000010000000000000008   @   2025-01-22T14:45:47.661869Z\
Last Failed WAL:                -\
\
Instances status\
Name               Current LSN  Replication role              Status  QoS         Manager Version  Node\
----               -----------  ----------------              ------  ---         ---------------  ----\
cluster-primary-1  0/80000A0    Designated primary            OK      BestEffort  1.25.0           cnpg-1.25.0-control-plane\
cluster-primary-2  0/80000A0    Standby (in Replica Cluster)  OK      BestEffort  1.25.0           cnpg-1.25.0-control-plane\
cluster-primary-3  0/80000A0    Standby (in Replica Cluster)  OK      BestEffort  1.25.0           cnpg-1.25.0-control-plane
\f1\fs38 \
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \
\pard\pardeftab720\sa319\partightenfactor0
\cf9 1] New primary (Ex replica) cluster:\cf0 \
\pard\pardeftab720\partightenfactor0

\f2\fs40 \cf7 kubectl cnpg status cluster-replica -n replica\
\cf0 \
\pard\pardeftab720\sa240\partightenfactor0

\f0\b\fs38 \cf0 Output:\
\pard\pardeftab720\partightenfactor0

\f2\b0\fs34 \cf0 Cluster Summary\
Name                 replica/cluster-replica\
System ID:           7462748611985788958\
PostgreSQL Image:    ghcr.io/cloudnative-pg/postgresql:17.2\
Primary instance:    cluster-replica-1\
Primary start time:  2025-01-22 14:38:56 +0000 UTC (uptime 8m21s)\
Status:              Cluster in healthy state \
Instances:           3\
Ready instances:     3\
Size:                126M\
Current Write LSN:   0/90075A8 (Timeline: 2 - WAL File: 000000020000000000000009)\
\
Continuous Backup status\
First Point of Recoverability:  Not Available\
Working WAL archiving:          OK\
WALs waiting to be archived:    0\
Last Archived WAL:              00000002.history   @   2025-01-22T14:46:17.122585Z\
Last Failed WAL:                -\
\
Streaming Replication status\
Replication Slots Enabled\
Name               Sent LSN   Write LSN  Flush LSN  Replay LSN  Write Lag  Flush Lag  Replay Lag  State      Sync State  Sync Priority  Replication Slot\
----               --------   ---------  ---------  ----------  ---------  ---------  ----------  -----      ----------  -------------  ----------------\
cluster-replica-2  0/90075A8  0/90075A8  0/90075A8  0/90075A8   00:00:00   00:00:00   00:00:00    streaming  async       0              active\
cluster-replica-3  0/90075A8  0/90075A8  0/90075A8  0/90075A8   00:00:00   00:00:00   00:00:00    streaming  async       0              active\
\
Instances status\
Name               Current LSN  Replication role  Status  QoS         Manager Version  Node\
----               -----------  ----------------  ------  ---         ---------------  ----\
cluster-replica-1  0/90075A8    Primary           OK      BestEffort  1.25.0           cnpg-1.25.0-control-plane\
cluster-replica-2  0/90075A8    Standby (async)   OK      BestEffort  1.25.0           cnpg-1.25.0-control-plane\
cluster-replica-3  0/90075A8    Standby (async)   OK      BestEffort  1.25.0           cnpg-1.25.0-control-plane
\f1\fs38 \
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \
\pard\pardeftab720\sa321\partightenfactor0

\f0\b\fs70 \cf10 \outl0\strokewidth0 \strokec3 Task to Complete:\
===============\cf0 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls3\ilvl0
\f1\b0\fs46 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Set up a primary cluster named \cf7 cluster-master \cf0 in the \cf7 master\cf0  namespace with \cf7 2\cf0  instances.\
\ls3\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Create a replica cluster named \cf7 cluster-standby\cf0  in the \cf7 standby\cf0  namespace, also with \cf7 2\cf0  instances.\
\ls3\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Follow the steps outlined above to perform the promotion process.\
\ls3\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\cf7 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Record all results\cf0  in a text file to ensure they can be reviewed in the next session.
\fs24 \
\pard\pardeftab720\sa256\partightenfactor0

\f4\fs32 \cf11 \cb12 \outl0\strokewidth0 \
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \cb1 \
\pard\pardeftab720\partightenfactor0

\fs38 \cf0 \
\pard\pardeftab720\sa240\partightenfactor0
\cf0 \
\pard\pardeftab720\partightenfactor0
\cf5 \
\pard\pardeftab720\sa280\partightenfactor0

\f0\b\fs42 \cf0 \
}